
---

## 1 Сверточные нейронные сети (CNN)

Сверточные нейронные сети (CNN, Convolutional Neural Networks) — это тип искусственных нейронных сетей, предназначенный для работы с данными, имеющими структуру сетки, например, изображениями. Они широко используются в задачах компьютерного зрения, таких как классификация изображений, сегментация и обнаружение объектов. Основная идея свертки заключается в применении фильтров (или ядер) для выявления признаков на изображениях, таких как края, текстуры или более сложные паттерны.

### Основные слои сверточной нейронной сети:

1. **Сверточный слой (Convolutional layer)**  
   Это основной слой сети, который применяет несколько свёрток с фильтрами к входным данным. Каждый фильтр извлекает различные признаки, такие как края, углы и текстуры. Выходом свёртки является набор активаций, представляющих обнаруженные паттерны.

2. **Пулинговый слой (Pooling layer)**  
   Пулинг используется для уменьшения размерности данных, сохраняя при этом важную информацию. Обычно используется операция максимального или усреднённого объединения, которая помогает снизить вычислительные затраты и количество параметров модели.

3. **Полносвязный слой (Fully connected layer)**  
   На этом этапе нейронная сеть принимает признаки, извлечённые на предыдущих слоях, и преобразует их в итоговое решение. Например, вероятность классов в задаче классификации.

4. **Функция активации (Activation function)**  
   После каждого сверточного и полносвязного слоя применяется функция активации (например, ReLU), которая вводит нелинейность в модель, позволяя сети решать более сложные задачи.

   Эта структура позволяет сверточным нейронным сетям эффективно обрабатывать и анализировать визуальные данные, обеспечивая высокую точность в задачах, связанных с изображениями.

---

## 2 Оптимизатор в CNN

Оптимизатор в сверточных нейронных сетях (CNN) используется для обновления весов модели во время обучения, с целью минимизации ошибки (функции потерь) и улучшения качества предсказания.

### Где используется оптимизатор в CNN:

1. **Сверточные слои**: Оптимизатор обновляет веса фильтров, которые извлекают признаки из изображений, такие как края и текстуры.
   
2. **Пулинговые слои**: Хотя пулинг не обучаемый, оптимизатор корректирует веса слоёв, перед и после пулинга, что влияет на обработку признаков.

3. **Полносвязные слои**: Эти слои комбинируют признаки для окончательной классификации. Оптимизатор корректирует их веса для улучшения точности.

4. **Обратное распространение ошибки**: Оптимизатор обновляет веса сети на основе разницы между предсказаниями и реальными метками, улучшая обучение.

### Как оптимизатор влияет на процесс обучения:

- **Скорость обучения (Learning Rate)**: Оптимизатор регулирует этот параметр, влияя на скорость изменения весов. Если скорость обучения слишком высокая, обучение может стать нестабильным, а если слишком низкая — процесс обучения будет медленным.

- **Сходимость**: Оптимизатор помогает сети достичь минимальной ошибки (функции потерь), ускоряя сходимость модели к оптимальному решению.

- **Использование градиентов**: Оптимизаторы, такие как **Adam**, используют информацию о градиентах функции потерь, чтобы корректировать веса модели более эффективно, что помогает избежать локальных минимумов и ускоряет обучение.

---

## 3 Архитектура Inception

### Особенности:
#### Разреженная архитектура:
- Проблема: линейное наращивание сверточных слоев достаточно быстро себя исчерпывает.
- Идея: использование нелинейной разреженной архитектуры.

#### Конкатенация фильтров
- Проблема: при линейной структуре у нас признаки с рецептивного поля (область, которая участвует в вычислении данного нейрона) одного размера (ограниченного размером свертки).
- Идея: конкатенировать выходы сверток разного размера на слоях одной глубины.

#### Уменьшение сложности
- Проблема: при большом количестве карт много вычислений свертки.
- Идея: с помощью свертки  предварительно уменьшить количество карт.

<p align="center">
   <img src="https://github.com/user-attachments/assets/9f01c1ad-16f4-4596-bc3a-0b5b6c390947">
</p>

Сеть Inception состоит из множества Inception-блоков.

### Inception. Детали архитектуры
- Количество составных блоков около 100.
- Глубина 27 слоев, из них 22 - с обучаемыми параметрами.
- Перед последним полносвязным слоем - GAP.
- Введены два дополнительных классификатора в середине сети (борьба с затухающим градиентом, регуляризация).
- Функции потерь для дополнительных классификаторов домножаются на 0,3.
- Используется дропаут.

<p align="center">
   <img src="https://github.com/user-attachments/assets/8ffe8a22-8a42-4bd3-a08f-78e5d71c7843">
</p>

---




